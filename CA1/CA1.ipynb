{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fffd1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e297c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General help functions\n",
    "# Generate different Q, b, c\n",
    "def get_Q_b_c(n):\n",
    "    Q = np.random.rand(n,n)-0.5\n",
    "    Q = 10*Q @ Q.T\n",
    "    b = 5*(np.random.rand(n)-0.5)\n",
    "    c = 2*(np.random.rand(1)-0.5) # c is a scalar\n",
    "    return Q,b,c\n",
    "\n",
    "def cal_f(x, Q, b, c):\n",
    "    return 0.5 * x.T @ Q @ x + b @ x + c\n",
    "\n",
    "def cal_grad_f(x, Q, b):\n",
    "    return Q @ x + b\n",
    "\n",
    "# Find the largest eigenvalue of Q\n",
    "def find_max_and_min_eigenvalue(Q):\n",
    "    eigenvalues, _ = np.linalg.eigh(Q)\n",
    "    return np.max(eigenvalues), np.min(eigenvalues)\n",
    "\n",
    "# Find the inverse of Q\n",
    "def find_inverse(Q):\n",
    "    return np.linalg.inv(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea62175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Constant step size\n",
    "def grad_descent_with_constant_step(Q, b, c, epsilon, x0=None):\n",
    "    L, mu = find_max_and_min_eigenvalue(Q)\n",
    "    step_size = 2 / (L + mu)\n",
    "    if x0 is None:\n",
    "        x0 = np.zeros(Q.shape[0])\n",
    "    k = 0 # iteration counter\n",
    "    grad_cur = cal_grad_f(x0, Q, b)\n",
    "    x_cur = x0.copy()\n",
    "    while np.linalg.norm(grad_cur, ord=2) >= epsilon:\n",
    "        x_cur -= step_size * grad_cur\n",
    "        grad_cur = cal_grad_f(x_cur, Q, b)\n",
    "        k += 1\n",
    "    return x_cur, k, cal_f(x_cur, Q, b, c), np.linalg.norm(cal_grad_f(x_cur, Q, b), ord=2), L, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18ba72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Matrix Inversion\n",
    "def solve_by_matrix_inversion(Q, b, c):\n",
    "    x_star = -find_inverse(Q) @ b\n",
    "    f_star = cal_f(x_star, Q, b, c)\n",
    "    return x_star, f_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4daae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Parameters ===\n",
      "seed = 114, n = 10, epsilon = 1e-08, alpha_scale = 1\n",
      "=== Task1: Constant Step Size Gradient Descent ===\n",
      "iterations = 758\n",
      "f(x*) = -4.211898464266943\n",
      "x* = [ 0.51567596  0.47365676 -0.46934266  0.01250579 -1.11732094 -1.13177153\n",
      " -0.46193916  0.84591313 -1.52790235  0.87108662]\n",
      "||grad_f(x*)||_2 = 9.932428666677722e-09\n",
      "L  = 27.811818801552185\n",
      "mu = 0.3958415370832774\n",
      "\n",
      "=== Task2: Backtracking Line Search ===\n",
      "\n",
      "=== Task3: Matrix Inversion ===\n",
      "f(x*) = -4.211898464266943\n",
      "x* = [ 0.51567596  0.47365676 -0.46934266  0.01250579 -1.11732094 -1.13177153\n",
      " -0.46193916  0.84591313 -1.52790235  0.87108662]\n"
     ]
    }
   ],
   "source": [
    "# For Testing\n",
    "if __name__ == \"__main__\":\n",
    "    seed = 114\n",
    "    np.random.seed(seed)\n",
    "    n = 10\n",
    "    epsilon = 1e-8\n",
    "    Q, b, c = get_Q_b_c(n)\n",
    "    x0 = np.random.rand(n)\n",
    "    alpha_scale = 1\n",
    "    # Task 1\n",
    "    x_task1, k_task1, f_task1, grad_norm_task1, L, mu = grad_descent_with_constant_step(Q, b, c, epsilon, x0)\n",
    "    # Task 3\n",
    "    x_task3, f_task3 = solve_by_matrix_inversion(Q, b, c)\n",
    "\n",
    "    # print results\n",
    "    # print parameters\n",
    "    print(\"=== Parameters ===\")\n",
    "    print(f\"seed = {seed}, n = {n}, epsilon = {epsilon}, alpha_scale = {alpha_scale}\")\n",
    "    \n",
    "    # print task 1\n",
    "    print(\"=== Task1: Constant Step Size Gradient Descent ===\")\n",
    "    print(f\"iterations = {k_task1}\")\n",
    "    print(f\"f(x*) = {float(f_task1.item())}\")\n",
    "    print(f\"x* = {x_task1.astype(float)}\")\n",
    "    print(f\"||grad_f(x*)||_2 = {float(grad_norm_task1)}\")\n",
    "    print(f\"L  = {float(L)}\")\n",
    "    print(f\"mu = {float(mu)}\")\n",
    "\n",
    "    # print task 2\n",
    "    print(\"\\n=== Task2: Backtracking Line Search ===\")\n",
    "\n",
    "    # print task 3\n",
    "    print(\"\\n=== Task3: Matrix Inversion ===\")\n",
    "    print(f\"f(x*) = {float(f_task3.item())}\")\n",
    "    print(f\"x* = {x_task3.astype(float)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
