{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fffd1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e297c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General help functions\n",
    "# Generate different Q, b, c\n",
    "def get_Q_b_c(n):\n",
    "    Q = np.random.rand(n,n)-0.5\n",
    "    Q = 10*Q @ Q.T\n",
    "    b = 5*(np.random.rand(n)-0.5)\n",
    "    c = 2*(np.random.rand(1)-0.5) # c is a scalar\n",
    "    return Q,b,c\n",
    "\n",
    "def cal_f(x, Q, b, c):\n",
    "    return 0.5 * x.T @ Q @ x + b @ x + c\n",
    "\n",
    "def cal_grad_f(x, Q, b):\n",
    "    return Q @ x + b\n",
    "\n",
    "# Find the largest eigenvalue of Q\n",
    "def find_max_and_min_eigenvalue(Q):\n",
    "    eigenvalues, _ = np.linalg.eigh(Q)\n",
    "    return np.max(eigenvalues), np.min(eigenvalues)\n",
    "\n",
    "# Find the inverse of Q\n",
    "def find_inverse(Q):\n",
    "    return np.linalg.inv(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aea62175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Constant step size\n",
    "def grad_descent_with_constant_step(Q, b, c, epsilon, x0=None):\n",
    "    L, mu = find_max_and_min_eigenvalue(Q)\n",
    "    step_size = 2 / (L + mu)\n",
    "    if x0 is None:\n",
    "        x0 = np.zeros(Q.shape[0])\n",
    "    k = 0 # iteration counter\n",
    "    grad_cur = cal_grad_f(x0, Q, b)\n",
    "    x_cur = x0.copy()\n",
    "    while np.linalg.norm(grad_cur, ord=2) >= epsilon:\n",
    "        x_cur -= step_size * grad_cur\n",
    "        grad_cur = cal_grad_f(x_cur, Q, b)\n",
    "        k += 1\n",
    "    return x_cur, k, cal_f(x_cur, Q, b, c), np.linalg.norm(cal_grad_f(x_cur, Q, b), ord=2), L, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb1fde25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2: Armijo's rule\n",
    "def find_alpha_with_armijo(Q, b, c, x_k):\n",
    "    s = 1\n",
    "    sigma = 10e-5 # can be between 10^-5 to 10^-1\n",
    "    beta = 0.5 # can be between 1/10 to 1/2\n",
    "    alpha = beta*s\n",
    "\n",
    "    grad_k = cal_grad_f(x_k, Q, b)\n",
    "    d_k = -grad_k\n",
    "    f_k = cal_f(x_k, Q, b, c)\n",
    "\n",
    "    while cal_f(x_k + alpha * d_k, Q, b, c) > f_k + sigma * alpha * (grad_k @ d_k):\n",
    "        alpha = alpha * beta # Reduce the step size\n",
    "\n",
    "    return alpha\n",
    "\n",
    "\n",
    "def grad_descent_with_armijo(Q, b, c, epsilon, x0=None):\n",
    "    if x0 is None:\n",
    "        x0 = np.zeros(Q.shape[0])\n",
    "    k = 0 # iteration counter\n",
    "    grad_cur = cal_grad_f(x0, Q, b)\n",
    "    x_cur = x0.copy()\n",
    "    while np.linalg.norm(grad_cur, ord=2) >= epsilon:\n",
    "        step_size = find_alpha_with_armijo(Q, b, c, x_cur)\n",
    "        x_cur -= step_size * grad_cur\n",
    "        grad_cur = cal_grad_f(x_cur, Q, b)\n",
    "        k += 1\n",
    "    return x_cur, k, cal_f(x_cur, Q, b, c), np.linalg.norm(cal_grad_f(x_cur, Q, b), ord=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18ba72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Matrix Inversion\n",
    "def solve_by_matrix_inversion(Q, b, c):\n",
    "    x_star = -find_inverse(Q) @ b\n",
    "    f_star = cal_f(x_star, Q, b, c)\n",
    "    return x_star, f_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4daae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Testing\n",
    "if __name__ == \"__main__\":\n",
    "    seed = 114\n",
    "    np.random.seed(seed)\n",
    "    n = 10\n",
    "    epsilon = 1e-8\n",
    "    Q, b, c = get_Q_b_c(n)\n",
    "    x0 = np.random.rand(n)\n",
    "    alpha_scale = 1\n",
    "    # Task 1\n",
    "    x_task1, k_task1, f_task1, grad_norm_task1, L, mu = grad_descent_with_constant_step(Q, b, c, epsilon, x0)\n",
    "    # Task 2\n",
    "    x_task2, k_task2, f_task2, grad_norm_task2 = grad_descent_with_armijo(Q, b, c, epsilon, x0)\n",
    "    # Task 3\n",
    "    x_task3, f_task3 = solve_by_matrix_inversion(Q, b, c)\n",
    "\n",
    "    # print results\n",
    "    # print parameters\n",
    "    print(\"=== Parameters ===\")\n",
    "    print(f\"seed = {seed}, n = {n}, epsilon = {epsilon}, alpha_scale = {alpha_scale}\")\n",
    "    \n",
    "    # print task 1\n",
    "    print(\"=== Task1: Constant Step Size Gradient Descent ===\")\n",
    "    print(f\"iterations = {k_task1}\")\n",
    "    print(f\"f(x*) = {float(f_task1.item())}\")\n",
    "    print(f\"x* = {x_task1.astype(float)}\")\n",
    "    print(f\"||grad_f(x*)||_2 = {float(grad_norm_task1)}\")\n",
    "    print(f\"L  = {float(L)}\")\n",
    "    print(f\"mu = {float(mu)}\")\n",
    "\n",
    "    # print task 2\n",
    "    print(\"\\n=== Task2: Backtracking Line Search ===\")\n",
    "\n",
    "    # print task 3\n",
    "    print(\"\\n=== Task3: Matrix Inversion ===\")\n",
    "    print(f\"f(x*) = {float(f_task3.item())}\")\n",
    "    print(f\"x* = {x_task3.astype(float)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
